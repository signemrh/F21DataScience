Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% fabletools::forecast(h = 14)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
library(tidyverse)
library(data.table)
library(tsibble)
library(stringr)
library(feasts)
library(fable)
library(fabletools)
library(usmap)
library(fpp3)
# Set training data from 1992 to 2006
train <- t_full_data
train <- t_full_data %>%
filter(State_ab == "CA") %>%
filter_index("1997" ~ "2006")
# Fit the models
gdp_fit <- train %>%
model(
Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% fabletools::forecast(h = 14)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
library(forecast)
# Set training data from 1992 to 2006
train <- t_full_data
train <- t_full_data %>%
filter(State_ab == "CA") %>%
filter_index("1997" ~ "2006")
# Fit the models
gdp_fit <- train %>%
model(
Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% forecast(h = 14)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
# Set training data from 1992 to 2006
train <- t_full_data
train <- t_full_data %>%
filter(State_ab == "CA") %>%
filter_index("1997" ~ "2006")
# Fit the models
gdp_fit <- train %>%
model(
Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% forecast::forecast(h = 14)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
View(t_full_data)
# Set training data from 1992 to 2006
train <- t_full_data
train <- t_full_data %>%
filter(State_ab == "CA") %>%
filter_index("1997" ~ "2006")
# Fit the models
gdp_fit <- train %>%
model(
Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% forecast(h = 14)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
# Set training data from 1992 to 2006
train <- t_full_data
train <- t_full_data %>%
filter(State_ab == "CA") %>%
filter_index("1997" ~ "2006")
# Fit the models
gdp_fit <- train %>%
model(
Mean = MEAN(FAT_capita))
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% forecast(h = 2)
autoplot(gdp_fc)
# Plot forecasts against actual values
gdp_fc %>%
autoplot(train, level = NULL)
# Generate forecasts for 14 quarters
gdp_fc <- gdp_fit %>% fable::forecast(h = 2)
model_results <- t_full_data %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
forecast(h = 2)
report()
model_results <- t_full_data %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
report()
model_results <- t_full_data %>%
filter(State_ab == "CA") %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
forecast(h = 2)
model_results <- t_full_data %>%
filter(State_ab == "CA") %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
forecast(h = 2)
gdp_model_results <- t_full_data %>%
model(TSLM(GDP_capita)) %>%
report()
fat_model_results <- t_full_data %>%
model(TSLM(FAT_capita)) %>%
report()
View(gdp_model_results)
View(fat_model_results)
# prepare dataframe for plot
us_plot_prep <- n_full_data %>%
rename(state = State_ab) %>%
group_by(state) %>%
summarise(mean_fa = sum(fatality))
us_plot_prep <- model_results %>%
rename(state = State_ab)
# create us map with number of fatalities
usa_plot <- plot_usmap(data = us_plot_prep, values = "p_value", color = "grey", labels = TRUE, label_color = "black") +
scale_fill_gradient(low = "cadetblue1", high = "cadetblue4", na.value = "grey50", # the colors for the states
guide = "colourbar", #for continuous colour bar
name = "P-value") + #Giving the scale a title
theme(legend.position = "right") #Positioning the scale to the right
usa_plot$layers[[2]]$aes_params$size <- 2.7 #Change the size of the abbreviations)
#View plot
print(usa_plot)
View(pop_data)
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=";")
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=";")
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
View(pop_data2020)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=";")
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=";")
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read_csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
pop_datahis = read_csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv")
pop_datahis = read.csv2("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
View(pop_data2020)
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)
View(pop_data2020)
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019,
NAME != "United States", NAME != "	Northeast Region")
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019) %>%
filter(NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
View(pop_data2020)
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019) %>%
filter(NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019) %>%
filter(NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
View(pop_data2020)
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)
filter(pop_data2020, NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
pop_data2020 <-  filter(pop_data2020, NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
pop_data2020 <-  filter(pop_data2020, NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico" )
View(pop_datahis)
pop_datahis = read.csv2("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read.csv2("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",")
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-08")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-16")
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-8",
header = TRUE,
stringsAsFactors = FALSE))
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-8",
header = TRUE,
stringsAsFactors = FALSE)
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-8", header = FALSE, stringsAsFactors = FALSE)
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep=",", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep = "", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
View(pop_datahis)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep = ";", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep = ";", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
View(pop_datahis)
View(pop_long)
# change from wide to long format
pop_long <- gather(pop_data2020, Year, pop, Y2021:Y2020, factor_key=TRUE)
View(pop_data2020)
# change from wide to long format
pop_long <- gather(pop_data2020, Year, pop, CENSUS2010POP:POPESTIMATE2019, factor_key=TRUE)
View(pop_long)
# change from wide to long format
pop_long <- gather(pop_data2020, Column, pop, CENSUS2010POP:POPESTIMATE2019, factor_key=TRUE)
pop_long$Year <- as.numeric(gsub("\\D", "", Column))
pop_long$Year <- as.numeric(gsub("\\D", "", pop_long$Column))
pop_datahis <- select(pop_datahis, Name, Year, Resident.Population)
pop_datahis <-  filter(pop_datahis, Name != "United States" | Name != "Northeast Region" | Name != "Midwest Region" | Name != "South Region" | Name != "West Region" | Name != "Puerto Rico")
pop_datahis <-  filter(pop_datahis, Name != "United States" | Name != "Northeast Region" | Name != "Midwest Region" | Name != "South Region" | Name != "West Region" | Name != "Puerto Rico")
View(pop_datahis)
View(pop_datahis)
pop_datahis <-  filter(pop_datahis, Name != "United States" | Name != "Northeast Region" | Name != "Midwest Region" | Name != "South Region" | Name != "West Region" | Name != "Puerto Rico")
View(pop_datahis)
pop_datahis1 <-  filter(pop_datahis, Name != "United States" | Name != "Northeast Region" | Name != "Midwest Region" | Name != "South Region" | Name != "West Region" | Name != "Puerto Rico")
pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico")
View(pop_datahis)
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)
pop_data2020 <-  filter(pop_data2020, NAME != "United States" | NAME != "Northeast Region" | NAME != "Midwest Region" | NAME != "South Region" | NAME != "West Region" | NAME != "Puerto Rico")
View(pop_data2020)
pop_data2020 <-  filter(pop_data2020, NAME != "United States" & NAME != "Northeast Region" & NAME != "Midwest Region" & NAME != "South Region" & NAME != "West Region" & NAME != "Puerto Rico")
View(pop_data2020)
pop_datahis$Resident.Population <- as.numeric(gsub(",","",pop_datahis$Resident.Population))
View(pop_datahis)
pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico" & Year >= 1990 & Year < 2010 )
View(pop_datahis)
pop_datahis <- pop_datahis %>%
rename(
pop = Resident.Population)
View(pop_datahis)
pop_datahis <- pop_datahis %>%
rename(
pop = Resident.Population,
NAME = Name)
pop_long <- select(pop_long, NAME, Year, pop)
View(pop_long)
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)
pop_data2020 <-  filter(pop_data2020, NAME != "United States" & NAME != "Northeast Region" & NAME != "Midwest Region" & NAME != "South Region" & NAME != "West Region" & NAME != "Puerto Rico")
# change from wide to long format
pop_long <- gather(pop_data2020, Column, pop, CENSUS2010POP:POPESTIMATE2019, factor_key=TRUE)
pop_long$Year <- as.numeric(gsub("\\D", "", pop_long$Column))
pop_long <- select(pop_long, NAME, Year, pop)
# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep = ";", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
pop_datahis <- select(pop_datahis, Name, Year, Resident.Population)
pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico" & Year >= 1990 & Year < 2010 )
pop_datahis$Resident.Population <- as.numeric(gsub(",","",pop_datahis$Resident.Population))
pop_datahis <- pop_datahis %>%
rename(
pop = Resident.Population,
NAME = Name)
View(pop_datahis)
# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_historicdata.csv", sep = ";", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
View(pop_datahis)
# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/censushis.csv", sep = ";", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
View(pop_datahis)
# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/censushis.csv", sep = ",", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
View(pop_datahis)
pop_datahis <- select(pop_datahis, Name, Year, Resident.Population)
pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico" & Year >= 1990 & Year < 2010 )
pop_datahis$Resident.Population <- as.numeric(gsub(",","",pop_datahis$Resident.Population))
pop_datahis <- pop_datahis %>%
rename(
pop = Resident.Population,
NAME = Name)
View(pop_datahis)
View(pop_datahis)
View(pop_long)
full_pop <- rbind(pop_datahis, pop_long)
View(full_pop)
full_pop <- full_pop %>%
rename(
NAME = State)
full_pop <- full_pop %>%
rename(
State = NAME)
# order by state and date
full_pop <- full_pop[order( full_pop[,1], full_pop[,2] ),]
# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")
# select relevant columns
pop_data2020 <- pop_data2020 %>%
select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)
pop_data2020 <-  filter(pop_data2020, NAME != "United States" & NAME != "Northeast Region" & NAME != "Midwest Region" & NAME != "South Region" & NAME != "West Region" & NAME != "Puerto Rico")
pop_data2020$Y1991 <- NA
pop_data2020$Y1992 <- NA
pop_data2020$Y1993 <- NA
pop_data2020$Y1994 <- NA
pop_data2020$Y1995 <- NA
pop_data2020$Y1996 <- NA
pop_data2020$Y1997 <- NA
pop_data2020$Y1998 <- NA
pop_data2020$Y1999 <- NA
pop_data2020$Y2001 <- NA
pop_data2020$Y2002 <- NA
pop_data2020$Y2003 <- NA
pop_data2020$Y2004 <- NA
pop_data2020$Y2005 <- NA
pop_data2020$Y2006 <- NA
pop_data2020$Y2007 <- NA
pop_data2020$Y2008 <- NA
pop_data2020$Y2009 <- NA
# change from wide to long format
pop_long <- gather(pop_data2020, Column, pop, CENSUS2010POP:Y2009, factor_key=TRUE)
View(pop_long)
pop_long$Year <- as.numeric(gsub("\\D", "", pop_long$Column))
pop_long <- select(pop_long, NAME, Year, pop)
# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/censushis.csv", sep = ",", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)
pop_datahis <- select(pop_datahis, Name, Year, Resident.Population)
pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico" & Year >= 1990 & Year < 2010 )
pop_datahis$Resident.Population <- as.numeric(gsub(",","",pop_datahis$Resident.Population))
pop_datahis <- pop_datahis %>%
rename(
pop = Resident.Population,
NAME = Name)
full_pop <- rbind(pop_datahis, pop_long)
full_pop <- full_pop %>%
rename(
State = NAME)
# order by state and date
full_pop <- full_pop[order( full_pop[,1], full_pop[,2] ),]
View(full_pop)
# interpolate missing values
full_pop <- full_pop %>%
group_by(State) %>%
mutate(PopInterp = na.approx(pop, na.rm=FALSE))
library(tidyverse)
library(data.table)
library(tsibble)
library(stringr)
library(feasts)
library(fable)
library(fabletools)
library(usmap)
library(fpp3)
# interpolate missing values
full_pop <- full_pop %>%
group_by(State) %>%
mutate(PopInterp = na.approx(pop, na.rm=FALSE))
library(zoo)
# interpolate missing values
full_pop <- full_pop %>%
group_by(State) %>%
mutate(PopInterp = na.approx(pop, na.rm=FALSE))
View(full_pop)
# make it uppercase to fit the full data
pop_long$State <- toupper(pop_long$State)
# make it uppercase to fit the full data
full_pop$State <- toupper(full_pop$State)
# make population into millions
n_full_data <- mutate(n_full_data, Pop_mil = PopInterp/1000000)
# take GDP per capita
n_full_data <- mutate(n_full_data, GDP_capita = GDP/Pop_mil)
n_full_data <- mutate(n_full_data, FAT_capita = fatality/Pop_mil)
#merge onto the old data
n_full_data <- full_data %>%
right_join(full_pop, by=c("State","Year"))
full_pop$Year <- as.character(full_pop$Year)
#merge onto the old data
n_full_data <- full_data %>%
right_join(full_pop, by=c("State","Year"))
# make population into millions
n_full_data <- mutate(n_full_data, Pop_mil = PopInterp/1000000)
# take GDP per capita
n_full_data <- mutate(n_full_data, GDP_capita = GDP/Pop_mil)
n_full_data <- mutate(n_full_data, FAT_capita = fatality/Pop_mil)
# Change the states to abbreviations
ab_list <- c("alabama"= "AL", "alaska" = "AK", "arizona" = "AZ", "arkansas" = "AR", "california" = "CA","colorado" = "CO","connecticut" = "CT","delaware" = "DE", "district of columbia" = "DC","florida" = "FL","georgia" = "GA","hawaii" = "HI","idaho" = "ID","illinois" = "IL","indiana" = "IN","iowa" = "IA","kansas" = "KS","kentucky" = "KY","louisiana" = "LA","maine" = "ME","maryland" = "MD","massachusetts" = "MA","michigan" = "MI","minnesota" = "MN","mississippi" = "MS","missouri" = "MO","montana" = "MT","nebraska" = "NE","nevada" = "NV","new hampshire" = "NH","new jersey" = "NJ","new mexico" = "NM","new york" = "NY","north carolina" = "NC","north dakota" = "ND","ohio" = "OH","oklahoma" = "OK","oregon" = "OR","pennsylvania" = "PA","rhode island" = "RI","south carolina" = "SC","south dakota" = "SD","tennessee" = "TN","texas" = "TX","utah" = "UT","vermont" = "VT","virginia" = "VA","washington" = "WA","west virginia" = "WV","wisconsin" = "WI","wyoming" = "WY")
# lowercase everything
n_full_data$State_ab <- tolower(n_full_data$State)
ab_var <- n_full_data$State_ab
# loop over all the state names and replace with abbreviations
for (i in 1:length(ab_list)) {
ab_var <- ab_var %>% str_replace(names(ab_list)[i], ab_list[i])
}
# append the new abbriviations to the dataframe
n_full_data$State_ab <- ab_var
# correct naming error
n_full_data$State_ab <- gsub("west VA", "WV", n_full_data$State_ab)
# make the full data into a tsibble
t_full_data <- as_tsibble(n_full_data, key = State_ab, index = Date)
View(t_full_data)
View(n_full_data)
# select the years needed and remove puerto rico since it is not part of the full dataframe
full_pop <- subset(full_pop, Year>"1996" & Year<"2020")
#merge onto the old data
n_full_data <- full_data %>%
right_join(full_pop, by=c("State","Year"))
# make population into millions
n_full_data <- mutate(n_full_data, Pop_mil = PopInterp/1000000)
# take GDP per capita
n_full_data <- mutate(n_full_data, GDP_capita = GDP/Pop_mil)
n_full_data <- mutate(n_full_data, FAT_capita = fatality/Pop_mil)
# Change the states to abbreviations
ab_list <- c("alabama"= "AL", "alaska" = "AK", "arizona" = "AZ", "arkansas" = "AR", "california" = "CA","colorado" = "CO","connecticut" = "CT","delaware" = "DE", "district of columbia" = "DC","florida" = "FL","georgia" = "GA","hawaii" = "HI","idaho" = "ID","illinois" = "IL","indiana" = "IN","iowa" = "IA","kansas" = "KS","kentucky" = "KY","louisiana" = "LA","maine" = "ME","maryland" = "MD","massachusetts" = "MA","michigan" = "MI","minnesota" = "MN","mississippi" = "MS","missouri" = "MO","montana" = "MT","nebraska" = "NE","nevada" = "NV","new hampshire" = "NH","new jersey" = "NJ","new mexico" = "NM","new york" = "NY","north carolina" = "NC","north dakota" = "ND","ohio" = "OH","oklahoma" = "OK","oregon" = "OR","pennsylvania" = "PA","rhode island" = "RI","south carolina" = "SC","south dakota" = "SD","tennessee" = "TN","texas" = "TX","utah" = "UT","vermont" = "VT","virginia" = "VA","washington" = "WA","west virginia" = "WV","wisconsin" = "WI","wyoming" = "WY")
# lowercase everything
n_full_data$State_ab <- tolower(n_full_data$State)
ab_var <- n_full_data$State_ab
# loop over all the state names and replace with abbreviations
for (i in 1:length(ab_list)) {
ab_var <- ab_var %>% str_replace(names(ab_list)[i], ab_list[i])
}
# append the new abbriviations to the dataframe
n_full_data$State_ab <- ab_var
# correct naming error
n_full_data$State_ab <- gsub("west VA", "WV", n_full_data$State_ab)
# make the full data into a tsibble
t_full_data <- as_tsibble(n_full_data, key = State_ab, index = Date)
# plot
# fatality
autoplot(t_full_data, FAT_capita)+
labs(y = "Fatalities", x = "Year", title = "Fatalities pr. state")
# GDP
autoplot(t_full_data, GDP_capita)+
labs(y = "$US", x = "Year", title = "GDP pr. capita pr. state")
# Look at the relationship
t_full_data %>%
ggplot(aes(x = FAT_capita, y = GDP_capita)) +
labs(y = "GDP (quarterly % change)",
x = "Fatality (quarterly % change)") +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
# simple model with
gdp_model_results <- t_full_data %>%
model(TSLM(GDP_capita)) %>%
report()
fat_model_results <- t_full_data %>%
model(TSLM(FAT_capita)) %>%
report()
model_results <- t_full_data %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
report()
t_full_data %>%
filter(State_ab == "ND") %>%
model(TSLM(FAT_capita ~ GDP_capita)) %>%
report()
model_results$Significant <- ifelse(model_results$p_value > 0.05, 0, 1)
# prepare dataframe for plot
us_plot_prep <- n_full_data %>%
rename(state = State_ab) %>%
group_by(state) %>%
summarise(mean_fa = sum(fatality))
us_plot_prep <- model_results %>%
rename(state = State_ab)
# create us map with number of fatalities
usa_plot <- plot_usmap(data = us_plot_prep, values = "p_value", color = "grey", labels = TRUE, label_color = "black") +
scale_fill_gradient(low = "cadetblue1", high = "cadetblue4", na.value = "grey50", # the colors for the states
guide = "colourbar", #for continuous colour bar
name = "P-value") + #Giving the scale a title
theme(legend.position = "right") #Positioning the scale to the right
usa_plot$layers[[2]]$aes_params$size <- 2.7 #Change the size of the abbreviations)
#View plot
print(usa_plot)
View(us_plot_prep)
# prepare dataframe for plot
us_plot_prep <- n_full_data %>%
rename(state = State_ab) %>%
group_by(state) %>%
summarise(mean_fa = sum(fatality))
us_plot_prep <- model_results %>%
rename(state = State_ab)
# create us map with number of fatalities
usa_plot <- plot_usmap(data = us_plot_prep, values = "Significant", color = "grey", labels = TRUE, label_color = "black") +
scale_fill_gradient(low = "cadetblue1", high = "cadetblue4", na.value = "grey50", # the colors for the states
guide = "colourbar", #for continuous colour bar
name = "P-value") + #Giving the scale a title
theme(legend.position = "right") #Positioning the scale to the right
usa_plot$layers[[2]]$aes_params$size <- 2.7 #Change the size of the abbreviations)
#View plot
print(usa_plot)
View(pop_datahis)
