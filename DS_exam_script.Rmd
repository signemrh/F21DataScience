---
title: "Data Science - Exam"
output: pdf_document
---

## Script for Data Science exam

# Libraries

```{r}
library(tidyverse)
library(data.table)
library(tsibble)
library(stringr)
library(feasts)
library(fable)
library(fabletools)
library(usmap)
library(fpp3)
library(zoo)
```


# Introduction to project

This project seeks to investigate the relationship between fatalities in car crashes and GDP in each state in USA.  

# Data 

This chunk loads all the data for GDP
- GDP is in Millions of Dollars

```{r}

setwd("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/GDP data/")
files <- list.files()

# create an empty list to store the data from the files
data_list <- list()

# loop over all the files in the folder
for(i in 1:length(files)){
  file_name <- files[i]
  d = fread(file_name, sep=",")

  #Change columns names
  colnames(d) <- c("Date","GDP")

  # Split the string by "_"
  filenames_vec <- strsplit(file_name, split = "_")[[1]]

  # Create new column for state
  d$State <- filenames_vec[2] # extract state name from filename
  d$State <- sub("*\\.csv", "", d$State) # remove the .csv from the column
  data_list[[i]] <- d # add the data to the list
}

# rbind all the data from the lists
gdp_data <- rbindlist(data_list) 


```


This chunk loads all the accident data

```{r}
setwd("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Fatality data/Data")
files <- list.files()

# create an empty list to store the data from the files
data_list <- list()

# loop over all the files in the folder
for(i in 1:length(files)){
  file_name <- files[i]
  d = fread(file_name, sep=",")
  
  # select columns
  d = subset(d, select=c("STATE", "MONTH", "DAY", "YEAR", "HOUR", "MINUTE", "VE_FORMS", "DAY_WEEK", "FATALS", "ST_CASE"))

  # Split the string by "_"
  filenames_vec <- strsplit(file_name, split = "_")[[1]]

  # Create new column for state
  d$FYear <- filenames_vec[2] # extract state name from filename
  d$FYear <- sub("*\\.csv", "", d$FYear) # remove the .csv from the column
  d$FYear <- sub("*\\.CSV", "", d$FYear)
  data_list[[i]] <- d # add the data to the list
}

# rbind all the data from the lists
acc_data <- rbindlist(data_list) 

# add leading 0 if less than 2 digits
acc_data$DAY <- str_pad(acc_data$DAY, 2, pad = "0") 
acc_data$MONTH <- str_pad(acc_data$MONTH, 2, pad = "0")

# make a full date column 
acc_data$Date <- paste(acc_data$DAY, acc_data$MONTH, acc_data$FYear,sep="-")

acc_data <- mutate(acc_data, Date = as.Date(Date, format = "%d-%m-%Y"))

# investigate NA's 
no_na <- filter(acc_data, !is.na(Date))
na_data <- filter(acc_data, is.na(Date))

# group by day to remove duplicates
group_acc_data <- no_na %>%
  group_by(STATE, FYear) %>%
  summarise(fatality = sum(FATALS)) # %>%
 # filter(!is.na(Date))

# make a copy of dataframe 
t_acc_data <- group_acc_data

```


```{r}
# Make states into names instead of numbers 
t_acc_data$STATE[t_acc_data$STATE == 1] <- "Alabama"   
t_acc_data$STATE[t_acc_data$STATE == 2] <- "Alaska"
t_acc_data$STATE[t_acc_data$STATE == 4] <- "Arizona"   
t_acc_data$STATE[t_acc_data$STATE == 5] <- "Arkansas"   
t_acc_data$STATE[t_acc_data$STATE == 6] <- "California"   
t_acc_data$STATE[t_acc_data$STATE == 8] <- "Colorado"   
t_acc_data$STATE[t_acc_data$STATE == 9] <- "Connecticut"   
t_acc_data$STATE[t_acc_data$STATE == 10] <- "Delaware"   
t_acc_data$STATE[t_acc_data$STATE == 11] <- "District of Columbia"   
t_acc_data$STATE[t_acc_data$STATE == 12] <- "Florida"   
t_acc_data$STATE[t_acc_data$STATE == 13] <- "Georgia"   
t_acc_data$STATE[t_acc_data$STATE == 15] <- "Hawaii"   
t_acc_data$STATE[t_acc_data$STATE == 16] <- "Idaho"   
t_acc_data$STATE[t_acc_data$STATE == 17] <- "Illinois"   
t_acc_data$STATE[t_acc_data$STATE == 18] <- "Indiana"   
t_acc_data$STATE[t_acc_data$STATE == 19] <- "Iowa"   
t_acc_data$STATE[t_acc_data$STATE == 20] <- "Kansas"   
t_acc_data$STATE[t_acc_data$STATE == 21] <- "Kentucky"   
t_acc_data$STATE[t_acc_data$STATE == 22] <- "Louisiana"   
t_acc_data$STATE[t_acc_data$STATE == 23] <- "Maine"   
t_acc_data$STATE[t_acc_data$STATE == 24] <- "Maryland"   
t_acc_data$STATE[t_acc_data$STATE == 25] <- "Massachusetts"   
t_acc_data$STATE[t_acc_data$STATE == 26] <- "Michigan"   
t_acc_data$STATE[t_acc_data$STATE == 27] <- "Minnesota"   
t_acc_data$STATE[t_acc_data$STATE == 28] <- "Mississippi"   
t_acc_data$STATE[t_acc_data$STATE == 29] <- "Missouri"   
t_acc_data$STATE[t_acc_data$STATE == 30] <- "Montana"   
t_acc_data$STATE[t_acc_data$STATE == 31] <- "Nebraska"   
t_acc_data$STATE[t_acc_data$STATE == 32] <- "Nevada"   
t_acc_data$STATE[t_acc_data$STATE == 33] <- "New Hampshire"   
t_acc_data$STATE[t_acc_data$STATE == 34] <- "New Jersey"   
t_acc_data$STATE[t_acc_data$STATE == 35] <- "New Mexico"   
t_acc_data$STATE[t_acc_data$STATE == 36] <- "New York"
t_acc_data$STATE[t_acc_data$STATE == 37] <- "North Carolina"   
t_acc_data$STATE[t_acc_data$STATE == 38] <- "North Dakota"   
t_acc_data$STATE[t_acc_data$STATE == 39] <- "Ohio"   
t_acc_data$STATE[t_acc_data$STATE == 40] <- "Oklahoma"   
t_acc_data$STATE[t_acc_data$STATE == 41] <- "Oregon"   
t_acc_data$STATE[t_acc_data$STATE == 42] <- "Pennsylvania"   
t_acc_data$STATE[t_acc_data$STATE == 43] <- "Puerto Rico"   
t_acc_data$STATE[t_acc_data$STATE == 44] <- "Rhode Island"   
t_acc_data$STATE[t_acc_data$STATE == 45] <- "South Carolina"   
t_acc_data$STATE[t_acc_data$STATE == 46] <- "South Dakota"   
t_acc_data$STATE[t_acc_data$STATE == 47] <- "Tennessee"   
t_acc_data$STATE[t_acc_data$STATE == 48] <- "Texas"   
t_acc_data$STATE[t_acc_data$STATE == 49] <- "Utah"   
t_acc_data$STATE[t_acc_data$STATE == 50] <- "Vermont"   
t_acc_data$STATE[t_acc_data$STATE == 52] <- "Virgin Islands"   
t_acc_data$STATE[t_acc_data$STATE == 51] <- "Virginia"   
t_acc_data$STATE[t_acc_data$STATE == 53] <- "Washington"  
t_acc_data$STATE[t_acc_data$STATE == 54] <- "West Virginia"  
t_acc_data$STATE[t_acc_data$STATE == 55] <- "Wisconsin"  
t_acc_data$STATE[t_acc_data$STATE == 56] <- "Wyoming"  

# make it uppercase to fit the GDP dataframe
t_acc_data$STATE <- toupper(t_acc_data$STATE)

```

# Merge of data frames

```{r}
# make two columns to match by in the dataframes
#t_acc_data$Year <- substr(t_acc_data$Date, start = 1, stop = 4)
t_acc_data$Year <- t_acc_data$FYear
gdp_data$Year <- substr(gdp_data$Date, start = 1, stop = 4)

# remove 2020 from GDP data
gdp_data <- filter(gdp_data, Year != "2020")

# rename column
t_acc_data <- t_acc_data %>% 
  rename(
    State = STATE)

# GDP rename some of the states
gdp_data$State[gdp_data$State == "NORTHDAKOTA"] <- "NORTH DAKOTA"   
gdp_data$State[gdp_data$State == "SOUTHDAKOTA"] <- "SOUTH DAKOTA"   
gdp_data$State[gdp_data$State == "NEWMEXICO"] <- "NEW MEXICO"   
gdp_data$State[gdp_data$State == "WESTVIRGINA"] <- "WEST VIRGINIA"  
gdp_data$State[gdp_data$State == "NEWYORK"] <- "NEW YORK"  
gdp_data$State[gdp_data$State == "NORTHCAROLINA"] <- "NORTH CAROLINA"  
gdp_data$State[gdp_data$State == "NEWJERSEY"] <- "NEW JERSEY"  
gdp_data$State[gdp_data$State == "SOUTHCAROLINA"] <- "SOUTH CAROLINA"  
gdp_data$State[gdp_data$State == "NEWHAMPSHIRE"] <- "NEW HAMPSHIRE"  
gdp_data$State[gdp_data$State == "DISTRICTOFCOLUMBIA"] <- "DISTRICT OF COLUMBIA"  
gdp_data$State[gdp_data$State == "RHODEISLAND"] <- "RHODE ISLAND" 
gdp_data$State[gdp_data$State == "ILLIONOIS"] <- "ILLINOIS" 


# merge dataframes
full_data <- t_acc_data %>% 
  right_join(gdp_data, by=c("State","Year"))

```


# Population data

```{r}

# load data with populations
pop_data2020 = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/Census_2010-2020.csv", sep=",")

# select relevant columns
pop_data2020 <- pop_data2020 %>%
  select(NAME, CENSUS2010POP, POPESTIMATE2011, POPESTIMATE2011, POPESTIMATE2012, POPESTIMATE2013, POPESTIMATE2014,
         POPESTIMATE2015, POPESTIMATE2016, POPESTIMATE2017, POPESTIMATE2018, POPESTIMATE2019)

pop_data2020 <-  filter(pop_data2020, NAME != "United States" & NAME != "Northeast Region" & NAME != "Midwest Region" & NAME != "South Region" & NAME != "West Region" & NAME != "Puerto Rico")

# prepare years that needs to be interpolated 
pop_data2020$Y1991 <- NA
pop_data2020$Y1992 <- NA
pop_data2020$Y1993 <- NA
pop_data2020$Y1994 <- NA
pop_data2020$Y1995 <- NA
pop_data2020$Y1996 <- NA
pop_data2020$Y1997 <- NA
pop_data2020$Y1998 <- NA
pop_data2020$Y1999 <- NA
pop_data2020$Y2001 <- NA
pop_data2020$Y2002 <- NA
pop_data2020$Y2003 <- NA
pop_data2020$Y2004 <- NA
pop_data2020$Y2005 <- NA
pop_data2020$Y2006 <- NA
pop_data2020$Y2007 <- NA
pop_data2020$Y2008 <- NA
pop_data2020$Y2009 <- NA

# change from wide to long format
pop_long <- gather(pop_data2020, Column, pop, CENSUS2010POP:Y2009, factor_key=TRUE)

# extract numbers from column
pop_long$Year <- as.numeric(gsub("\\D", "", pop_long$Column))

pop_long <- select(pop_long, NAME, Year, pop)

# Second data frame
pop_datahis = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/Population_data/censushis.csv", sep = ",", encoding = "UTF-8", header = TRUE, stringsAsFactors = FALSE)

pop_datahis <- select(pop_datahis, Name, Year, Resident.Population)

pop_datahis <-  filter(pop_datahis, Name != "United States" & Name != "Northeast Region" & Name != "Midwest Region" & Name != "South Region" & Name != "West Region" & Name != "Puerto Rico" & Year >= 1990 & Year < 2010 )

pop_datahis$Resident.Population <- as.numeric(gsub(",","",pop_datahis$Resident.Population))

pop_datahis <- pop_datahis %>% 
  rename(
    pop = Resident.Population, 
    NAME = Name)


full_pop <- rbind(pop_datahis, pop_long)

full_pop <- full_pop %>% 
  rename(
    State = NAME)

# order by state and date
full_pop <- full_pop[order( full_pop[,1], full_pop[,2] ),]

# interpolate missing values
full_pop <- full_pop %>%
  group_by(State) %>%
  mutate(PopInterp = na.approx(pop, na.rm=FALSE))

# make it uppercase to fit the full data
full_pop$State <- toupper(full_pop$State)
full_pop$Year <- as.character(full_pop$Year)

# select the years needed and remove puerto rico since it is not part of the full dataframe
full_pop <- subset(full_pop, Year>"1996" & Year<"2020")

#merge onto the old data
n_full_data <- full_data %>% 
 right_join(full_pop, by=c("State","Year"))

```


# Preprocessing

- Adjusting for population
- Abbreviate states

```{r}

# make population into millions
n_full_data <- mutate(n_full_data, Pop_mil = PopInterp/1000000)

# take GDP per capita
n_full_data <- mutate(n_full_data, GDP_capita = GDP/Pop_mil)

n_full_data <- mutate(n_full_data, FAT_capita = fatality/Pop_mil)


```

```{r}
# Change the states to abbreviations
ab_list <- c("alabama"= "AL", "alaska" = "AK", "arizona" = "AZ", "arkansas" = "AR", "california" = "CA","colorado" = "CO","connecticut" = "CT","delaware" = "DE", "district of columbia" = "DC","florida" = "FL","georgia" = "GA","hawaii" = "HI","idaho" = "ID","illinois" = "IL","indiana" = "IN","iowa" = "IA","kansas" = "KS","kentucky" = "KY","louisiana" = "LA","maine" = "ME","maryland" = "MD","massachusetts" = "MA","michigan" = "MI","minnesota" = "MN","mississippi" = "MS","missouri" = "MO","montana" = "MT","nebraska" = "NE","nevada" = "NV","new hampshire" = "NH","new jersey" = "NJ","new mexico" = "NM","new york" = "NY","north carolina" = "NC","north dakota" = "ND","ohio" = "OH","oklahoma" = "OK","oregon" = "OR","pennsylvania" = "PA","rhode island" = "RI","south carolina" = "SC","south dakota" = "SD","tennessee" = "TN","texas" = "TX","utah" = "UT","vermont" = "VT","virginia" = "VA","washington" = "WA","west virginia" = "WV","wisconsin" = "WI","wyoming" = "WY")

# lowercase everything
n_full_data$State_ab <- tolower(n_full_data$State)

ab_var <- n_full_data$State_ab

# loop over all the state names and replace with abbreviations
for (i in 1:length(ab_list)) {
  ab_var <- ab_var %>% str_replace(names(ab_list)[i], ab_list[i])
}

# append the new abbriviations to the dataframe
n_full_data$State_ab <- ab_var

# correct naming error
n_full_data$State_ab <- gsub("west VA", "WV", n_full_data$State_ab)
```



# Time series 

The dataframe has to be converted into a tsibble object to enable the full time series analysis. 

```{r}
# make the full data into a tsibble 
t_full_data <- as_tsibble(n_full_data, key = State_ab, index = Date)
```


# Investigate the data

```{r}
# plot 
# fatality
autoplot(t_full_data, FAT_capita)+
  labs(y = "Fatalities", x = "Year", title = "Fatalities pr. state")

# GDP
autoplot(t_full_data, GDP_capita)+
  labs(y = "$US", x = "Year", title = "GDP pr. capita pr. state")

# Look at the relationship
t_full_data %>%
  ggplot(aes(x = FAT_capita, y = GDP_capita)) +
  labs(y = "GDP",
       x = "Fatality") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

```

# Model


```{r}
# simple model with 
gdp_model_results <- t_full_data %>%
  model(TSLM(GDP_capita)) %>%
  report()

fat_model_results <- t_full_data %>%
  model(TSLM(FAT_capita)) %>%
  report()

# model with fatalities predicted by GDP
model_results <- t_full_data %>%
  model(TSLM(FAT_capita ~ GDP_capita)) %>%
  report()

# investigate a single state
t_full_data %>%
  filter(State_ab == "ND") %>%
  model(TSLM(FAT_capita ~ GDP_capita)) %>%
  report()

# create column to see if model is significant or not - 1 = significant, 0 = not significant
model_results$Significant <- ifelse(model_results$p_value > 0.05, 0, 1)

```

```{r}

temp_data <- t_full_data %>%
  filter(Year >= 1999) %>%
  filter(State_ab == "AK")

fit_data <- temp_data %>%
  model(TSLM(FAT_capita))

fc_data <- forecast(fit_data)

fc_data %>%
  autoplot(temp_data) +
  labs(
    title = "Forecasts of beer production using regression",
    y = "megalitres"
  )

```



```{r}
# prepare dataframe for plot
us_plot_prep <- n_full_data %>% 
  rename(state = State_ab) %>%
  group_by(state) %>% 
  summarise(mean_fa = sum(fatality)) 


us_plot_prep <- model_results %>%
  rename(state = State_ab)

# create us map with number of fatalities
usa_plot <- plot_usmap(data = us_plot_prep, values = "p_value", color = "grey", labels = TRUE, label_color = "black") + 
  scale_fill_gradient(low = "cadetblue1", high = "cadetblue4", na.value = "grey50", # the colors for the states
                      guide = "colourbar", #for continuous colour bar
                      name = "P-value") + #Giving the scale a title
                      theme(legend.position = "right") #Positioning the scale to the right

usa_plot$layers[[2]]$aes_params$size <- 2.7 #Change the size of the abbreviations)


#View plot
print(usa_plot)
```





# OLD THINGS TO BE DELETED
```{r}
# load data with populations
pop_data = read.csv("/Users/signeholdgaard/OneDrive - Aarhus universitet/Master/8 semester/Data Science/Exam/Coding/Data/pop_data.csv", sep=";")

# prepare years that needs to be interpolated 
pop_data$Y1991 <- NA
pop_data$Y1992 <- NA
pop_data$Y1993 <- NA
pop_data$Y1994 <- NA
pop_data$Y1995 <- NA
pop_data$Y1996 <- NA
pop_data$Y1997 <- NA
pop_data$Y1998 <- NA
pop_data$Y1999 <- NA
pop_data$Y2001 <- NA
pop_data$Y2002 <- NA
pop_data$Y2003 <- NA
pop_data$Y2004 <- NA
pop_data$Y2005 <- NA
pop_data$Y2006 <- NA
pop_data$Y2007 <- NA
pop_data$Y2008 <- NA
pop_data$Y2009 <- NA
pop_data$Y2011 <- NA
pop_data$Y2012 <- NA
pop_data$Y2013 <- NA
pop_data$Y2014 <- NA
pop_data$Y2015 <- NA
pop_data$Y2016 <- NA
pop_data$Y2017 <- NA
pop_data$Y2018 <- NA
pop_data$Y2019 <- NA
pop_data$Y2020 <- NA

# change from wide to long format
pop_long <- gather(pop_data, Year, pop, Y2021:Y2020, factor_key=TRUE)

# remove the Y in the year column
pop_long$Year <- sub("Y*", "", pop_long$Year)

#pop_long$date <- as.Date(ISOdate(pop_long$Year, 1, 1))

# order by state and date
pop_long <- pop_long[order( pop_long[,1], pop_long[,2] ),]

# interpolate missing values
pop_long <- pop_long %>%
  group_by(State) %>%
  mutate(PopInterp = na.approx(pop, na.rm=FALSE))

# select the years needed and remove puerto rico since it is not part of the full dataframe
pop_long <- subset(pop_long, Year>"1996" & Year<"2020" & State != "Puerto Rico")

# make it uppercase to fit the full data
pop_long$State <- toupper(pop_long$State)
```










